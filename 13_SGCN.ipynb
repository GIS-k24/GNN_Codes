{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Signed Sage Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "from tqdm import trange\n",
    "from scipy import sparse\n",
    "from texttable import Texttable\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add, scatter_mean\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(size, tensor):\n",
    "    stdv = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(ListModule, self).__init__()\n",
    "        idx = 0\n",
    "        for module in args:\n",
    "            self.add_module(str(idx), module)\n",
    "            idx += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self._modules):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._modules.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedSAGEConvolution(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, norm=True, norm_embed=True, bias=True):\n",
    "        super(SignedSAGEConvolution, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.norm = norm\n",
    "        self.norm_embed = norm_embed\n",
    "        self.weight = Parameter(torch.Tensor(self.in_channels, out_channels))  # 32*3\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.weight.size(0)\n",
    "        uniform(size, self.weight)\n",
    "        uniform(size, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}({}, {})\".format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedSAGEConvolutionBase(SignedSAGEConvolution):\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = remove_self_loops(edge_index, None)  # 去除自连接的边(A-A)\n",
    "        row, col = edge_index  # 初始，终止节点编号;\n",
    "        # scatter_mean: https://blog.csdn.net/StarfishCu/article/details/108853080\n",
    "        if self.norm:\n",
    "            out = scatter_mean(x[col], row, dim=0, dim_size=x.size(0))  # scatter_mean函数表示，row索引位置相加，返会结果; dim_size表示返回的节点，如果不在row中，则为0\n",
    "        else:\n",
    "            out = scatter_add(x[col], row, dim=0, dim_size=x.size(0))\n",
    "        # 节点聚合周围邻居之后的信息; [5881, 64]\n",
    "        out = torch.cat((out, x), 1)  # 将聚合特征和原始特征拼接\n",
    "        out = torch.matmul(out, self.weight)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        if self.norm_embed:\n",
    "            out = F.normalize(out, p=2, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedSAGEConvolutionDeep(SignedSAGEConvolution):\n",
    "    def forward(self, x_1, x_2, edge_index_pos, edge_index_neg):\n",
    "        edge_index_pos, _ = remove_self_loops(edge_index_pos, None)\n",
    "        edge_index_pos, _ = add_self_loops(edge_index_pos, num_nodes=x_1.size(0))\n",
    "        edge_index_neg, _ = remove_self_loops(edge_index_neg, None)\n",
    "        edge_index_neg, _ = add_self_loops(edge_index_neg, num_nodes=x_2.size(0))\n",
    "\n",
    "        row_pos, col_pos = edge_index_pos\n",
    "        row_neg, col_neg = edge_index_neg\n",
    "\n",
    "        if self.norm:  # pos: [x_1:balance features; x_2:unbalance features]  neg :[x_1:unbalance features; x_2:balance features]\n",
    "            out_1 = scatter_mean(x_1[col_pos], row_pos, dim=0, dim_size=x_1.size(0))\n",
    "            out_2 = scatter_mean(x_2[col_neg], row_neg, dim=0, dim_size=x_2.size(0))\n",
    "        else:\n",
    "            out_1 = scatter_add(x_1[col_pos], row_pos, dim=0, dim_size=x_1.size(0))\n",
    "            out_2 = scatter_add(x_2[col_neg], row_neg, dim=0, dim_size=x_2.size(0))\n",
    "\n",
    "        out = torch.cat((out_1, out_2, x_1), 1)\n",
    "        out = torch.matmul(out, self.weight)\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        if self.norm_embed:\n",
    "            out = F.normalize(out, p=2, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc(targets, predictions, edges):\n",
    "    neg_ratio = len(edges[\"negative_edges\"]) / edges[\"ecount\"]\n",
    "    targets = [0 if target == 1 else 1 for target in targets]\n",
    "    auc = roc_auc_score(targets, predictions)\n",
    "    f1 = f1_score(targets, [1 if p > neg_ratio else 0 for p in  predictions])\n",
    "    return auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_general_features(args):\n",
    "    X = np.array(pd.read_csv(args.features_path))\n",
    "    return X\n",
    "\n",
    "def create_spectral_features(args, positive_edges, negative_edges, node_count):\n",
    "    p_edges = positive_edges + [[edge[1], edge[0]] for edge in positive_edges]  # 转换成无向图的点边关系\n",
    "    n_edges = negative_edges + [[edge[1], edge[0]] for edge in negative_edges]\n",
    "    train_edges = p_edges + n_edges  # 所有点边信息\n",
    "    index_1 = [edge[0] for edge in train_edges]  # src\n",
    "    index_2 = [edge[1] for edge in train_edges]  # dst\n",
    "    values = [1] * len(p_edges) + [-1] * len(n_edges)  # label定义\n",
    "    shaping = (node_count, node_count)  # 节点数量，构造点边关系矩阵\n",
    "    signed_A = sparse.csr_matrix(sparse.coo_matrix((values, (index_1, index_2)),  # 构建稀疏邻接矩阵\n",
    "                                                   shape=shaping,\n",
    "                                                   dtype=np.float32))\n",
    "    # SVD分解，构造节点特征就是节点邻接矩阵的降维\n",
    "    svd = TruncatedSVD(\n",
    "        n_components=args.reduction_dimensions,\n",
    "        n_iter=args.reduction_iterations,\n",
    "        random_state=args.seed\n",
    "    )\n",
    "    svd.fit(signed_A)\n",
    "    X = svd.components_.T  # 降维后的特征\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_features(args, positive_edges, negative_edges, node_count):\n",
    "    if args.spectral_features:\n",
    "        X = create_spectral_features(args, positive_edges, negative_edges, node_count)  # 构造节点特征，为邻接矩阵降维结果\n",
    "    else:\n",
    "        X = create_general_features(args)  # origin\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedGraphConvolutionalNetwork(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Signed Graph Convolutional Network Class.\n",
    "    For details see: Signed Graph Convolutional Network.\n",
    "    Tyler Derr, Yao Ma, and Jiliang Tang ICDM, 2018.\n",
    "    https://arxiv.org/abs/1808.06354\n",
    "    \"\"\"\n",
    "    def __init__(self, device, args, X):\n",
    "        super(SignedGraphConvolutionalNetwork, self).__init__()\n",
    "        \"\"\"\n",
    "        SGCN Initialization.\n",
    "        :param device: Device for calculations.\n",
    "        :param args: Arguments object.\n",
    "        :param X: Node features.\n",
    "        \"\"\"\n",
    "        self.args = args\n",
    "        torch.manual_seed(self.args.seed)\n",
    "        self.device = device\n",
    "        self.X = X\n",
    "        self.setup_layers()  # 构建SGCN，Layer\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Adding Base Layers, Deep Signed GraphSAGE layers.\n",
    "        Assing Regression Parameters if the model is not a single layer model.\n",
    "        \"\"\"\n",
    "        self.nodes = range(self.X.shape[0])\n",
    "        self.neurons = self.args.layers  # 网络层参数\n",
    "        self.layers = len(self.neurons)  # 网络层数\n",
    "        self.positive_base_aggregator = SignedSAGEConvolutionBase(self.X.shape[1]*2,  # 64*2 -> 32  # 构建第一层SGCN\n",
    "                                                                  self.neurons[0]).to(self.device)\n",
    "\n",
    "        self.negative_base_aggregator = SignedSAGEConvolutionBase(self.X.shape[1]*2,\n",
    "                                                                  self.neurons[0]).to(self.device)\n",
    "        self.positive_aggregators = []\n",
    "        self.negative_aggregators = []\n",
    "        for i in range(1, self.layers):  # l>1 层SGCN\n",
    "            self.positive_aggregators.append(SignedSAGEConvolutionDeep(3*self.neurons[i-1],\n",
    "                                                                       self.neurons[i]).to(self.device))\n",
    "\n",
    "            self.negative_aggregators.append(SignedSAGEConvolutionDeep(3*self.neurons[i-1],\n",
    "                                                                       self.neurons[i]).to(self.device))\n",
    "\n",
    "        self.positive_aggregators = ListModule(*self.positive_aggregators)  # 给予网络层编号\n",
    "        self.negative_aggregators = ListModule(*self.negative_aggregators)\n",
    "        self.regression_weights = Parameter(torch.Tensor(4*self.neurons[-1], 3))  # 4*32=128; edge_label参数\n",
    "        init.xavier_normal_(self.regression_weights)\n",
    "\n",
    "    def calculate_regression_loss(self, z, target):\n",
    "        \"\"\"\n",
    "        Calculating the regression loss for all pairs of nodes.\n",
    "        :param z: Hidden vertex representations.\n",
    "        :param target: Target vector.\n",
    "        :return loss_term: Regression loss.\n",
    "        :return predictions_soft: Predictions for each vertex pair.\n",
    "        \"\"\"\n",
    "        pos = torch.cat((self.positive_z_i, self.positive_z_j), 1)  # 拼接pos: [i,j]\n",
    "        neg = torch.cat((self.negative_z_i, self.negative_z_j), 1)  # 拼接neg: [i,j]\n",
    "\n",
    "        surr_neg_i = torch.cat((self.negative_z_i, self.negative_z_k), 1)  # 不连接边: [i,k]\n",
    "        surr_neg_j = torch.cat((self.negative_z_j, self.negative_z_k), 1)\n",
    "        surr_pos_i = torch.cat((self.positive_z_i, self.positive_z_k), 1)\n",
    "        surr_pos_j = torch.cat((self.positive_z_j, self.positive_z_k), 1)\n",
    "\n",
    "        features = torch.cat((pos, neg, surr_neg_i, surr_neg_j, surr_pos_i, surr_pos_j))\n",
    "        predictions = torch.mm(features, self.regression_weights)\n",
    "        predictions_soft = F.log_softmax(predictions, dim=1)\n",
    "        loss_term = F.nll_loss(predictions_soft, target)  # 对数损失\n",
    "        return loss_term, predictions_soft\n",
    "\n",
    "    def calculate_positive_embedding_loss(self, z, positive_edges):\n",
    "        \"\"\"\n",
    "        Calculating the loss on the positive edge embedding distances\n",
    "        :param z: Hidden vertex representation.\n",
    "        :param positive_edges: Positive training edges.\n",
    "        :return loss_term: Loss value on positive edge embedding.\n",
    "        \"\"\"\n",
    "        self.positive_surrogates = [random.choice(self.nodes) for node in range(positive_edges.shape[1])]  # 随机positive数量相同的选择不连接节点\n",
    "        self.positive_surrogates = torch.from_numpy(np.array(self.positive_surrogates, dtype=np.int64).T)\n",
    "        self.positive_surrogates = self.positive_surrogates.type(torch.long).to(self.device)  # 转换成torch格式\n",
    "        positive_edges = torch.t(positive_edges)  # positive_edge转置\n",
    "        self.positive_z_i = z[positive_edges[:, 0], :]  # row的embedding\n",
    "        self.positive_z_j = z[positive_edges[:, 1], :]  # col的embedding\n",
    "        self.positive_z_k = z[self.positive_surrogates, :]  # 随机的节点的embedding\n",
    "        norm_i_j = torch.norm(self.positive_z_i-self.positive_z_j, 2, 1, True).pow(2)\n",
    "        norm_i_k = torch.norm(self.positive_z_i-self.positive_z_k, 2, 1, True).pow(2)\n",
    "        term = norm_i_j-norm_i_k\n",
    "        term[term < 0] = 0\n",
    "        loss_term = term.mean()\n",
    "        return loss_term\n",
    "\n",
    "    def calculate_negative_embedding_loss(self, z, negative_edges):\n",
    "        \"\"\"\n",
    "        Calculating the loss on the negative edge embedding distances\n",
    "        :param z: Hidden vertex representation.\n",
    "        :param negative_edges: Negative training edges.\n",
    "        :return loss_term: Loss value on negative edge embedding.\n",
    "        \"\"\"\n",
    "        self.negative_surrogates = [random.choice(self.nodes) for node in range(negative_edges.shape[1])]\n",
    "        self.negative_surrogates = torch.from_numpy(np.array(self.negative_surrogates, dtype=np.int64).T)\n",
    "        self.negative_surrogates = self.negative_surrogates.type(torch.long).to(self.device)\n",
    "        negative_edges = torch.t(negative_edges)\n",
    "        self.negative_z_i = z[negative_edges[:, 0], :]\n",
    "        self.negative_z_j = z[negative_edges[:, 1], :]\n",
    "        self.negative_z_k = z[self.negative_surrogates, :]\n",
    "        norm_i_j = torch.norm(self.negative_z_i-self.negative_z_j, 2, 1, True).pow(2)\n",
    "        norm_i_k = torch.norm(self.negative_z_i-self.negative_z_k, 2, 1, True).pow(2)\n",
    "        term = norm_i_k-norm_i_j\n",
    "        term[term < 0] = 0\n",
    "        loss_term = term.mean()\n",
    "        return loss_term\n",
    "\n",
    "    def calculate_loss_function(self, z, positive_edges, negative_edges, target):\n",
    "        \"\"\"\n",
    "        Calculating the embedding losses, regression loss and weight regularization loss.\n",
    "        :param z: Node embedding.\n",
    "        :param positive_edges: Positive edge pairs.\n",
    "        :param negative_edges: Negative edge pairs.\n",
    "        :param target: Target vector.\n",
    "        :return loss: Value of loss.\n",
    "        \"\"\"\n",
    "        loss_term_1 = self.calculate_positive_embedding_loss(z, positive_edges)\n",
    "        loss_term_2 = self.calculate_negative_embedding_loss(z, negative_edges)\n",
    "        regression_loss, self.predictions = self.calculate_regression_loss(z, target)\n",
    "        loss_term = regression_loss+self.args.lamb*(loss_term_1+loss_term_2)\n",
    "        return loss_term\n",
    "\n",
    "    def forward(self, positive_edges, negative_edges, target):\n",
    "        \"\"\"\n",
    "        Model forward propagation pass. Can fit deep and single layer SGCN models.\n",
    "        :param positive_edges: Positive edges.\n",
    "        :param negative_edges: Negative edges.\n",
    "        :param target: Target vectors.\n",
    "        :return loss: Loss value.\n",
    "        :return self.z: Hidden vertex representations.\n",
    "        \"\"\"\n",
    "        self.h_pos, self.h_neg = [], []\n",
    "        self.h_pos.append(torch.tanh(self.positive_base_aggregator(self.X, positive_edges)))  # self.X=[5881,64]; positive_edges=[2,14624]\n",
    "        self.h_neg.append(torch.tanh(self.negative_base_aggregator(self.X, negative_edges)))\n",
    "        for i in range(1, self.layers):\n",
    "            self.h_pos.append(torch.tanh(self.positive_aggregators[i-1](self.h_pos[i-1], self.h_neg[i-1], positive_edges, negative_edges)))\n",
    "            self.h_neg.append(torch.tanh(self.negative_aggregators[i-1](self.h_neg[i-1], self.h_pos[i-1], positive_edges, negative_edges)))\n",
    "        self.z = torch.cat((self.h_pos[-1], self.h_neg[-1]), 1)\n",
    "        loss = self.calculate_loss_function(self.z, positive_edges, negative_edges, target)\n",
    "        return loss, self.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedGCNTrainer(object):\n",
    "    \"\"\"\n",
    "    Object to train and score the SGCN, log the model behaviour and save the output.\n",
    "    \"\"\"\n",
    "    def __init__(self, args, edges):\n",
    "        \"\"\"\n",
    "        Constructing the trainer instance and setting up logs.\n",
    "        :param args: Arguments object.\n",
    "        :param edges: Edge data structure with positive and negative edges separated.\n",
    "        \"\"\"\n",
    "        self.args = args\n",
    "        self.edges = edges\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.setup_logs()\n",
    "\n",
    "    def setup_logs(self):\n",
    "        \"\"\"\n",
    "        Creating a log dictionary.\n",
    "        \"\"\"\n",
    "        self.logs = {}\n",
    "        self.logs[\"parameters\"] = vars(self.args)\n",
    "        self.logs[\"performance\"] = [[\"Epoch\", \"AUC\", \"F1\"]]\n",
    "        self.logs[\"training_time\"] = [[\"Epoch\", \"Seconds\"]]\n",
    "\n",
    "    def setup_dataset(self):\n",
    "        \"\"\"\n",
    "        Creating train and test split.\n",
    "        \"\"\"\n",
    "        self.positive_edges, self.test_positive_edges = train_test_split(self.edges[\"positive_edges\"],  # postive的点边关系\n",
    "                                                                         test_size=self.args.test_size)\n",
    "\n",
    "        self.negative_edges, self.test_negative_edges = train_test_split(self.edges[\"negative_edges\"],\n",
    "                                                                         test_size=self.args.test_size)\n",
    "        self.ecount = len(self.positive_edges + self.negative_edges)  # 训练样本数量\n",
    "        # SVD分解，邻接矩阵，为节点特征;\n",
    "        self.X = setup_features(self.args,\n",
    "                                self.positive_edges,  # 训练样本\n",
    "                                self.negative_edges,\n",
    "                                self.edges[\"ncount\"])  # 点的数量\n",
    "        # positive样本的点边关系转换成torch类型\n",
    "        self.positive_edges = torch.from_numpy(np.array(self.positive_edges,\n",
    "                                                        dtype=np.int64).T).type(torch.long).to(self.device)\n",
    "        # negative样本的点边关系\n",
    "        self.negative_edges = torch.from_numpy(np.array(self.negative_edges,\n",
    "                                                        dtype=np.int64).T).type(torch.long).to(self.device)\n",
    "        # label: [0],[1] 两个部分; [2]是两倍的点边数量-表示不连接的边; !!  np.array([0]*len(self.positive_edges) + [1]*len(self.negative_edges) + [2]*(self.ecount*2))\n",
    "        self.y = np.array([0]*len(self.positive_edges[0]) + [1]*len(self.negative_edges[0]) + [2]*(self.ecount*2))  #np.array([0 if i < int(self.ecount/2) else 1 for i in range(self.ecount)]+[2]*(self.ecount*2))\n",
    "        self.y = torch.from_numpy(self.y).type(torch.LongTensor).to(self.device)\n",
    "        self.X = torch.from_numpy(self.X).float().to(self.device)  # [5881,64]的input features\n",
    "\n",
    "    def score_model(self, epoch):\n",
    "        \"\"\"\n",
    "        Score the model on the test set edges in each epoch.\n",
    "        :param epoch: Epoch number.\n",
    "        \"\"\"\n",
    "        loss, self.train_z = self.model(self.positive_edges, self.negative_edges, self.y)\n",
    "        score_positive_edges = torch.from_numpy(np.array(self.test_positive_edges, dtype=np.int64).T).type(torch.long).to(self.device)\n",
    "        score_negative_edges = torch.from_numpy(np.array(self.test_negative_edges, dtype=np.int64).T).type(torch.long).to(self.device)\n",
    "        test_positive_z = torch.cat((self.train_z[score_positive_edges[0, :], :], self.train_z[score_positive_edges[1, :], :]), 1)\n",
    "        test_negative_z = torch.cat((self.train_z[score_negative_edges[0, :], :], self.train_z[score_negative_edges[1, :], :]), 1)\n",
    "        scores = torch.mm(torch.cat((test_positive_z, test_negative_z), 0), self.model.regression_weights.to(self.device))\n",
    "        probability_scores = torch.exp(F.softmax(scores, dim=1))\n",
    "        predictions = probability_scores[:, 0]/probability_scores[:, 0:2].sum(1)\n",
    "        predictions = predictions.cpu().detach().numpy()\n",
    "        targets = [0]*len(self.test_positive_edges) + [1]*len(self.test_negative_edges)\n",
    "        auc, f1 = calculate_auc(targets, predictions, self.edges)\n",
    "        self.logs[\"performance\"].append([epoch+1, auc, f1])\n",
    "\n",
    "    def create_and_train_model(self):\n",
    "        \"\"\"\n",
    "        Model training and scoring.\n",
    "        \"\"\"\n",
    "        print(\"\\nTraining started.\\n\")\n",
    "        self.model = SignedGraphConvolutionalNetwork(self.device, self.args, self.X).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                          lr=self.args.learning_rate,\n",
    "                                          weight_decay=self.args.weight_decay)\n",
    "        self.model.train()\n",
    "        self.epochs = trange(self.args.epochs, desc=\"Loss\")\n",
    "        for epoch in self.epochs:\n",
    "            start_time = time.time()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss, _ = self.model(self.positive_edges, self.negative_edges, self.y)\n",
    "            loss.backward()\n",
    "            self.epochs.set_description(\"SGCN (Loss=%g)\" % round(loss.item(), 4))\n",
    "            self.optimizer.step()\n",
    "            self.logs[\"training_time\"].append([epoch+1, time.time()-start_time])\n",
    "            if self.args.test_size > 0:\n",
    "                self.score_model(epoch)\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        Saving the embedding and model weights.\n",
    "        \"\"\"\n",
    "        print(\"\\nEmbedding is saved.\\n\")\n",
    "        self.train_z = self.train_z.cpu().detach().numpy()\n",
    "        embedding_header = [\"id\"] + [\"x_\" + str(x) for x in range(self.train_z.shape[1])]\n",
    "        self.train_z = np.concatenate([np.array(range(self.train_z.shape[0])).reshape(-1, 1), self.train_z], axis=1)\n",
    "        self.train_z = pd.DataFrame(self.train_z, columns=embedding_header)\n",
    "        self.train_z.to_csv(self.args.embedding_path, index=None)\n",
    "        \n",
    "        print(\"\\nRegression weights are saved.\\n\")\n",
    "        self.regression_weights = self.model.regression_weights.cpu().detach().numpy().T\n",
    "        regression_header = [\"x_\" + str(x) for x in range(self.regression_weights.shape[1])]\n",
    "        self.regression_weights = pd.DataFrame(self.regression_weights, columns=regression_header)\n",
    "        self.regression_weights.to_csv(self.args.regression_weights_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(args):\n",
    "    dataset = pd.read_csv(args.edge_path).values.tolist()\n",
    "    edges = {}\n",
    "    edges[\"positive_edges\"] = [edge[0:2] for edge in dataset if edge[2] == 1]  # postitive的edge\n",
    "    edges[\"negative_edges\"] = [edge[0:2] for edge in dataset if edge[2] == -1]  # negative的edge\n",
    "    edges[\"ecount\"] = len(dataset)  # 数据数量\n",
    "    edges[\"ncount\"] = len(set([edge[0] for edge in dataset]+[edge[1] for edge in dataset]))  # 所有节点的数量\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_printer(args):\n",
    "    args = vars(args)\n",
    "    keys = sorted(args.keys())\n",
    "    t = Texttable()\n",
    "    t.add_rows([[\"Parameter\", \"Value\"]])\n",
    "    t.add_rows([[k.replace(\"_\", \" \").capitalize(), args[k]] for k in keys])\n",
    "    print(t.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_printer(args):\n",
    "    args = vars(args)\n",
    "    keys = sorted(args.keys())\n",
    "    t = Texttable()\n",
    "    t.add_rows([[\"Parameter\", \"Value\"]])\n",
    "    t.add_rows([[k.replace(\"_\", \" \").capitalize(), args[k]] for k in keys])\n",
    "    print(t.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_printer(logs):\n",
    "    t = Texttable()\n",
    "    t.add_rows([per for i, per in enumerate(logs[\"performance\"]) if i % 10 == 0])\n",
    "    print(t.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_logs(args, logs):\n",
    "    with open(args.log_path, \"w\") as f:\n",
    "        json.dump(logs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"Run SGCN.\")\n",
    "    \n",
    "    parser.add_argument(\"--edge-path\", nargs=\"?\", default=r\"C:\\Users\\sss\\Desktop\\SGCN/input/bitcoin_otc.csv\", help=\"Edge list csv.\")\n",
    "    parser.add_argument(\"--features-path\", nargs=\"?\", default=r\"C:\\Users\\sss\\Desktop\\SGCN/input/bitcoin_otc.csv\", help=\"Edge list csv.\")\n",
    "    parser.add_argument(\"--embedding-path\", nargs=\"?\", default=r\"C:\\Users\\sss\\Desktop\\SGCN/output/embedding/bitcoin_otc_sgcn.csv\", help=\"Target embedding csv.\")\n",
    "    parser.add_argument(\"--regression-weights-path\", nargs=\"?\", default=r\"C:\\Users\\sss\\Desktop\\SGCN/output/weights/bitcoin_otc_sgcn.csv\", help=\"Regression weights csv.\")\n",
    "    # parser.add_argument(\"--log-path\", nargs=\"?\", default=r\"C:\\Users\\sss\\Desktop\\SGCN/logs/bitcoin_otc_logs.json\", help=\"Log json.\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100, help=\"Number of training epochs. Default is 100.\")\n",
    "    parser.add_argument(\"--reduction-iterations\", type=int, default=30, help=\"Number of SVD iterations. Default is 30.\")\n",
    "    parser.add_argument(\"--reduction-dimensions\", type=int, default=64, help=\"Number of SVD feature extraction dimensions. Default is 64.\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Random seed for sklearn pre-training. Default is 42.\")\n",
    "    parser.add_argument(\"--lamb\", type=float, default=1.0, help=\"Embedding regularization parameter. Default is 1.0.\")\n",
    "    parser.add_argument(\"--test-size\", type=float, default=0.2, help=\"Test dataset size. Default is 0.2.\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=0.01, help=\"Learning rate. Default is 0.01.\")\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=10**-5, help=\"Learning rate. Default is 10^-5.\")\n",
    "    parser.add_argument(\"--layers\", nargs=\"+\", type=int, help=\"Layer dimensions separated by space. E.g. 32 32.\")\n",
    "    parser.add_argument(\"--spectral-features\", dest=\"spectral_features\", action=\"store_true\")\n",
    "    parser.add_argument(\"--general-features\", dest=\"spectral_features\", action=\"store_false\")\n",
    "    \n",
    "    parser.set_defaults(spectral_features=True)\n",
    "    parser.set_defaults(layers=[32, 32])\n",
    "\n",
    "    return parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parameter_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------------------------------------+\n",
      "|        Edge path        |  C:\\Users\\sss\\Desktop\\SGCN/input/bitcoin_otc.csv   |\n",
      "+=========================+====================================================+\n",
      "| Embedding path          | C:\\Users\\sss\\Desktop\\SGCN/output/embedding/bitcoin |\n",
      "|                         | _otc_sgcn.csv                                      |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Epochs                  | 100                                                |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Features path           | C:\\Users\\sss\\Desktop\\SGCN/input/bitcoin_otc.csv    |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Lamb                    | 1                                                  |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Layers                  | [32, 32]                                           |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Learning rate           | 0.010                                              |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Reduction dimensions    | 64                                                 |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Reduction iterations    | 30                                                 |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Regression weights path | C:\\Users\\sss\\Desktop\\SGCN/output/weights/bitcoin_o |\n",
      "|                         | tc_sgcn.csv                                        |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Seed                    | 42                                                 |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Spectral features       | 1                                                  |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Test size               | 0.200                                              |\n",
      "+-------------------------+----------------------------------------------------+\n",
      "| Weight decay            | 0.000                                              |\n",
      "+-------------------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "tab_printer(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入数据\n",
    "args.edge_path = r'C:\\Users\\sss\\Desktop\\SGCN/input/bitcoin_otc.csv'\n",
    "args.features_path = r'C:\\Users\\sss\\Desktop\\SGCN/input/bitcoin_otc.csv'\n",
    "\n",
    "# 文件保存\n",
    "args.embedding_path = r'C:\\Users\\sss\\Desktop\\SGCN/output/embedding/bitcoin_otc_sgcn.csv'\n",
    "args.regression_weights_path = r'C:\\Users\\sss\\Desktop\\SGCN/output/weights/bitcoin_otc_sgcn.csv'\n",
    "# args.epochs = 1  # 测试模型【模型成功即可修改】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = read_graph(args)  # 导入训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loss:   0%|                                                                                    | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SGCN (Loss=0.6193): 100%|████████████████████████████████████████████████████████████| 100/100 [00:54<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SignedGCNTrainer(args, edges)\n",
    "trainer.setup_dataset()\n",
    "trainer.create_and_train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding is saved.\n",
      "\n",
      "\n",
      "Regression weights are saved.\n",
      "\n",
      "+-------+-------+-------+\n",
      "| Epoch |  AUC  |  F1   |\n",
      "+=======+=======+=======+\n",
      "| 10    | 0.708 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 20    | 0.695 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 30    | 0.662 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 40    | 0.700 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 50    | 0.757 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 60    | 0.774 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 70    | 0.776 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 80    | 0.788 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 90    | 0.786 | 0.921 |\n",
      "+-------+-------+-------+\n",
      "| 100   | 0.797 | 0.921 |\n",
      "+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "if args.test_size > 0:\n",
    "    trainer.save_model()\n",
    "    score_printer(trainer.logs)\n",
    "    # save_logs(args, trainer.logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
