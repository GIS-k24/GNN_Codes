{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import subprocess\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NUM_DIC = {\n",
    "    'epinions': 131828,\n",
    "    'slashdot': 82140,\n",
    "    'bitcoin_alpha': 3783,\n",
    "    'bitcoin_otc': 5881,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaExtra(object):\n",
    "    def __init__(self, dataset='epinions', k=1, debug=False):\n",
    "        filename = r'C:\\Users\\sss\\Desktop\\SiGAT/experiment-data/{}-train-{}.edgelist'.format(dataset, k)  # 导入训练数据\n",
    "        if debug:\n",
    "            filename = './test.edgelists'\n",
    "        res = self.init_edgelists(filename=filename)\n",
    "        self.pos_in_edgelists, self.pos_out_edgelists, self.neg_in_edgelists, self.neg_out_edgelists = res\n",
    "\n",
    "    def init_edgelists(self, filename=r'C:\\Users\\sss\\Desktop\\SiGAT/experiment-data/epinions-train-1.edgelist'):\n",
    "        \n",
    "        pos_out_edgelists = defaultdict(list)\n",
    "        neg_out_edgelists = defaultdict(list)\n",
    "        pos_in_edgelists = defaultdict(list)\n",
    "        neg_in_edgelists = defaultdict(list)\n",
    "        \n",
    "        with open(filename) as f:\n",
    "            for line in f.readlines():\n",
    "                x, y, z = line.split()\n",
    "                x = int(x)\n",
    "                y = int(y)\n",
    "                z = int(z)\n",
    "                \n",
    "                if z == 1:\n",
    "                    pos_out_edgelists[x].append(y)  # u->v; u向外指向v的有向边\n",
    "                    pos_in_edgelists[y].append(x)  # v->u: v被u指向\n",
    "                else:\n",
    "                    neg_out_edgelists[x].append(y)\n",
    "                    neg_in_edgelists[y].append(x)\n",
    "        return pos_in_edgelists, pos_out_edgelists, neg_in_edgelists, neg_out_edgelists\n",
    "\n",
    "    def get_pos_indegree(self, v):\n",
    "        return len(self.pos_in_edgelists[v])\n",
    "\n",
    "    def get_pos_outdegree(self, v):\n",
    "        return len(self.pos_out_edgelists[v])\n",
    "\n",
    "    def get_neg_indegree(self, v):\n",
    "        return len(self.neg_in_edgelists[v])\n",
    "\n",
    "    def get_neg_outdegree(self, v):\n",
    "        return len(self.neg_out_edgelists[v])\n",
    "\n",
    "    def common_neighbors(self, u, v):\n",
    "        u_neighbors = self.pos_in_edgelists[u] + self.neg_in_edgelists[u] + \\\n",
    "                      self.pos_out_edgelists[u] + self.neg_out_edgelists[u]\n",
    "        v_neighbors = self.pos_in_edgelists[v] + self.neg_in_edgelists[v] + \\\n",
    "                      self.pos_out_edgelists[v] + self.neg_out_edgelists[v]\n",
    "        return len(set(u_neighbors).intersection(set(v_neighbors)))\n",
    "\n",
    "    def feature_part1(self, u, v):\n",
    "        d_pos_in_u = self.get_pos_indegree(u)\n",
    "        d_neg_in_v = self.get_neg_indegree(v)\n",
    "        d_pos_out_u = self.get_pos_outdegree(u)\n",
    "        d_neg_out_v = self.get_neg_outdegree(v)\n",
    "\n",
    "        # d_pos_in_v = self.get_pos_indegree(v)\n",
    "        # d_neg_in_u = self.get_neg_indegree(u)\n",
    "        # d_pos_out_v = self.get_pos_outdegree(v)\n",
    "        # d_neg_out_u = self.get_neg_outdegree(u)\n",
    "\n",
    "        c_u_v = self.common_neighbors(u, v)\n",
    "        d_out_u = self.get_neg_outdegree(u) + self.get_pos_outdegree(u)\n",
    "        d_in_v = self.get_neg_indegree(v) + self.get_pos_indegree(v)\n",
    "        return d_pos_in_u, d_neg_in_v, d_pos_out_u, d_neg_out_v, c_u_v, d_out_u, d_in_v\n",
    "\n",
    "    def feature_part2(self, u, v):\n",
    "        \"\"\"\n",
    "        /^ \\v /^ \\^ /v \\v /v ^\\\n",
    "        ++\n",
    "        /^ \\v /^ \\^ /v \\v /v ^\\\n",
    "        +-\n",
    "        /^ \\v /^ \\^ /v \\v /v ^\\\n",
    "        -+\n",
    "        /^ \\v /^ \\^ /v \\v /v ^\\\n",
    "        --\n",
    "        \"\"\"\n",
    "        d1_1 = len(set(self.pos_out_edgelists[u]).intersection(set(self.pos_in_edgelists[v])))  # 集合交集\n",
    "        d1_2 = len(set(self.pos_out_edgelists[u]).intersection(set(self.neg_in_edgelists[v])))\n",
    "        d1_3 = len(set(self.neg_out_edgelists[u]).intersection(set(self.pos_in_edgelists[v])))\n",
    "        d1_4 = len(set(self.neg_out_edgelists[u]).intersection(set(self.neg_in_edgelists[v])))\n",
    "\n",
    "        d2_1 = len(set(self.pos_out_edgelists[u]).intersection(set(self.pos_out_edgelists[v])))\n",
    "        d2_2 = len(set(self.pos_out_edgelists[u]).intersection(set(self.neg_out_edgelists[v])))\n",
    "        d2_3 = len(set(self.neg_out_edgelists[u]).intersection(set(self.pos_out_edgelists[v])))\n",
    "        d2_4 = len(set(self.neg_out_edgelists[u]).intersection(set(self.neg_out_edgelists[v])))\n",
    "\n",
    "        d3_1 = len(set(self.pos_in_edgelists[u]).intersection(set(self.pos_out_edgelists[v])))\n",
    "        d3_2 = len(set(self.pos_in_edgelists[u]).intersection(set(self.neg_out_edgelists[v])))\n",
    "        d3_3 = len(set(self.neg_in_edgelists[u]).intersection(set(self.pos_out_edgelists[v])))\n",
    "        d3_4 = len(set(self.neg_in_edgelists[u]).intersection(set(self.neg_out_edgelists[v])))\n",
    "\n",
    "        d4_1 = len(set(self.pos_in_edgelists[u]).intersection(set(self.pos_in_edgelists[v])))\n",
    "        d4_2 = len(set(self.pos_in_edgelists[u]).intersection(set(self.neg_in_edgelists[v])))\n",
    "        d4_3 = len(set(self.neg_in_edgelists[u]).intersection(set(self.pos_in_edgelists[v])))\n",
    "        d4_4 = len(set(self.neg_in_edgelists[u]).intersection(set(self.neg_in_edgelists[v])))\n",
    "\n",
    "        return d1_1, d1_2, d1_3, d1_4, d2_1, d2_2, d2_3, d2_4, d3_1, d3_2, d3_3, d3_4, d4_1, d4_2, d4_3, d4_4\n",
    "\n",
    "    def get_features(self, u, v):\n",
    "        x11 = self.feature_part1(u, v)\n",
    "        x12 = self.feature_part2(u, v)\n",
    "        return x11 + x12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--devices', type=str, default='cpu', help='Devices')\n",
    "parser.add_argument('--seed', type=int, default=13, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.0005, help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0001, help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--dataset', default='bitcoin_alpha', help='Dataset')\n",
    "parser.add_argument('--dim', type=int, default=20, help='Embedding Dimension')\n",
    "parser.add_argument('--fea_dim', type=int, default=20, help='Feature Embedding Dimension')\n",
    "parser.add_argument('--batch_size', type=int, default=500, help='Batch Size')\n",
    "parser.add_argument('--dropout', type=float, default=0.0, help='Dropout k')\n",
    "parser.add_argument('--k', default=1, help='Folder k')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件输出\n",
    "\n",
    "OUTPUT_DIR = r'C:\\Users\\sss\\Desktop\\SiGAT\\embeddings\\sigat'\n",
    "if not os.path.exists(r'C:\\Users\\sss\\Desktop\\SiGAT\\embeddings'):\n",
    "    os.mkdir(r'C:\\Users\\sss\\Desktop\\SiGAT\\embeddings')\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x248ffefd270>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机种子\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_LOSS_RATIO = 1\n",
    "INTERVAL_PRINT = 20\n",
    "\n",
    "NUM_NODE = DATASET_NUM_DIC[args.dataset]  # \"bitcoin_alpha\"\n",
    "WEIGHT_DECAY = args.weight_decay\n",
    "NODE_FEAT_SIZE = args.fea_dim\n",
    "EMBEDDING_SIZE1 = args.dim\n",
    "DEVICES = torch.device(args.devices)\n",
    "LEARNING_RATE = args.lr\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "DROUPOUT = args.dropout\n",
    "K = args.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(DEVICES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # Encode features to embeddings\n",
    "    def __init__(self, features_lists, feature_dim, embed_dim, adj_lists, aggs):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.features_lists = features_lists  # features\n",
    "        self.feat_dim = feature_dim  # dim\n",
    "        self.adj_lists = adj_lists  # 38个motifs\n",
    "        self.aggs = aggs  # 38个motifs对应到的attention layer\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        for i, agg in enumerate(self.aggs):\n",
    "            self.add_module('agg_{}'.format(i), agg)  # 模块化的值\n",
    "            self.aggs[i] = agg.to(DEVICES)\n",
    "            \n",
    "        def init_weights(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "                \n",
    "        self.nonlinear_layer = nn.Sequential(\n",
    "            nn.Linear(self.feat_dim * (len(adj_lists) + 1), self.feat_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.feat_dim, self.embed_dim)\n",
    "        )\n",
    "        self.nonlinear_layer.apply(init_weights)\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        # Generates embeddings for nodes.\n",
    "        neigh_feats = [agg.forward(nodes, adj) for adj, agg in zip(self.adj_lists, self.aggs)]  # return 38 motifs GAT\n",
    "        self_feats = self.features_lists[0](torch.LongTensor(nodes).to(DEVICES))\n",
    "        combined = torch.cat([self_feats] + neigh_feats, 1)\n",
    "        combined = self.nonlinear_layer(combined)\n",
    "        return combined        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialSpmmFunction(torch.autograd.Function):\n",
    "    # Special function for only sparse region backpropataion layer\n",
    "    @staticmethod\n",
    "    def forward(ctx, indices, values, shape, b):\n",
    "        assert indices.requires_grad == False\n",
    "        a = torch.sparse_coo_tensor(indices, values, shape, device=DEVICES)  # 稀疏矩阵\n",
    "        ctx.save_for_backward(a, b)\n",
    "        ctx.N = shape[0]\n",
    "        return torch.matmul(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        a, b = ctx.saved_tensors\n",
    "        grad_values = grad_b = None\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_a_dense = grad_output.matmul(b.t())\n",
    "            edge_idx = a._indices()[0, :] * ctx.N + a._indices()[1, :]\n",
    "            grad_values = grad_a_dense.view(-1)[edge_idx]\n",
    "        if ctx.needs_input_grad[3]:\n",
    "            grad_b = a.t().matmul(grad_output)\n",
    "        return None, grad_values, None, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialSpmm(nn.Module):\n",
    "    def forward(self, indices, values, shape, b):\n",
    "        return SpecialSpmmFunction.apply(indices, values, shape, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionAggregator(nn.Module):\n",
    "    def __init__(self, features, in_dim, out_dim, node_num, dropout_rate=DROUPOUT, slope_ratio=0.1):\n",
    "        super(AttentionAggregator, self).__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.slope_ratio = slope_ratio\n",
    "        self.a = nn.Parameter(torch.FloatTensor(out_dim * 2, 1))  # attention参数; W1||W2\n",
    "        nn.init.kaiming_normal_(self.a.data)\n",
    "        self.speical_spmm = SpecialSpmm()  # 稀疏矩阵的梯度更新\n",
    "        \n",
    "        self.out_linear_layer = nn.Linear(self.in_dim, self.out_dim)  # W * h\n",
    "        self.unique_nodes_dict = np.zeros(node_num, dtype=np.int32)\n",
    "        \n",
    "    def forward(self, nodes, adj):\n",
    "        \"\"\"\n",
    "        nodes --- list of nodes in a batch\n",
    "        adj --- sp.sparse.csr_matrix\n",
    "        \"\"\"\n",
    "        node_pku = np.array(nodes)  # minbatch的节点\n",
    "        edges = np.array(adj[nodes, :].nonzero()).T  # 选择的邻接矩阵的边; 按照edges的行进行编号的\n",
    "        edges[:, 0] = node_pku[edges[:, 0]]  # 将node本身的index赋予到edges上\n",
    "        \n",
    "        unique_nodes_list = np.unique(np.hstack((np.unique(edges), np.array(nodes))))\n",
    "        \n",
    "        batch_node_num = len(unique_nodes_list)\n",
    "        # this dict can map new i to originial node id; 将新id映射到原始id上\n",
    "        self.unique_nodes_dict[unique_nodes_list] = np.arange(batch_node_num)  # 对每一个单词给予一个index\n",
    "        # 将之前的索引转换成新标记的索引（新标记的是从0开始到batch_node_num）\n",
    "        edges[:, 0] = self.unique_nodes_dict[edges[:, 0]]  # 赋予新的id\n",
    "        edges[:, 1] = self.unique_nodes_dict[edges[:, 1]]\n",
    "        \n",
    "        n2 = torch.LongTensor(unique_nodes_list).to(DEVICES)  # 旧的节点集合\n",
    "        new_embeddings = self.out_linear_layer(self.features(n2))  # W * h\n",
    "        \n",
    "        original_node_edge = np.array([self.unique_nodes_dict[nodes], self.unique_nodes_dict[nodes]]).T  # 自连接边\n",
    "        edges = np.vstack((edges, original_node_edge))  # 加入自连接边\n",
    "        edges = torch.LongTensor(edges).to(DEVICES)\n",
    "        \n",
    "        edge_h_2 = torch.cat((new_embeddings[edges[:, 0], :], new_embeddings[edges[:, 1], :]), dim=1)  # Whi||Whj\n",
    "        edges_h = torch.exp(F.leaky_relu(torch.einsum(\"ij, jl -> il\", [edge_h_2, self.a]), self.slope_ratio))  # attention系数\n",
    "        indices = edges\n",
    "                    # 稀疏矩阵计算     # 点边关系   # attention系数  #\n",
    "        row_sum = self.speical_spmm(edges.t(), edges_h[:, 0], torch.Size((batch_node_num, batch_node_num)), torch.ones(size=(batch_node_num, 1)).to(DEVICES))\n",
    "\n",
    "        results = self.speical_spmm(edges.t(), edges_h[:, 0], torch.Size((batch_node_num, batch_node_num)), new_embeddings)\n",
    "\n",
    "        output_emb = results.div(row_sum)  # 除法：GAT的输出结果\n",
    "        \n",
    "        return output_emb[self.unique_nodes_dict[nodes]]  # 返回minbatch中涉及到的node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiGAT(nn.Module):\n",
    "    def __init__(self, enc):\n",
    "        super(SiGAT, self).__init__()\n",
    "        self.enc = enc\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        embeds = self.enc(nodes)\n",
    "        return embeds\n",
    "    \n",
    "    def criterion(self, nodes, pos_neighbors, neg_neighbors):\n",
    "        pos_neighbors_list = [set.union(pos_neighbors[i]) for i in nodes]  # node的positive节点邻接\n",
    "        neg_neighbors_list = [set.union(neg_neighbors[i]) for i in nodes]  # node的negative节点邻接\n",
    "        unique_nodes_list = list(set.union(*pos_neighbors_list).union(*neg_neighbors_list).union(nodes))  # 节点集合\n",
    "        unique_nodes_dict = {n: i for i, n in enumerate(unique_nodes_list)}  # node: index\n",
    "        nodes_embs = self.enc(unique_nodes_list)  # 输出节点embedding\n",
    "        \n",
    "        loss_total = 0\n",
    "        for index, node in enumerate(nodes):\n",
    "            z1 = nodes_embs[unique_nodes_dict[node], :]  # 该节点的embedding\n",
    "            pos_neigs = list([unique_nodes_dict[i] for i in pos_neighbors[node]])  # 该节点的positive邻居节点\n",
    "            neg_neigs = list([unique_nodes_dict[i] for i in neg_neighbors[node]])  # 该节点的negative邻居节点\n",
    "            pos_num = len(pos_neigs)\n",
    "            neg_num = len(neg_neigs)\n",
    "\n",
    "            if pos_num > 0:\n",
    "                pos_neig_embs = nodes_embs[pos_neigs, :]  # positive邻居节点\n",
    "                loss_pku = -1 * torch.sum(F.logsigmoid(torch.einsum(\"nj, j -> n\", [pos_neig_embs, z1])))\n",
    "                loss_total += loss_pku\n",
    "            tmp_pku = 1 if neg_num == 0 else neg_num\n",
    "            C = pos_num // tmp_pku  # 正样本是负样本的多少倍\n",
    "            if C == 0:\n",
    "                C = 1\n",
    "            if neg_num > 0:\n",
    "                neg_neig_embs = nodes_embs[neg_neigs, :]\n",
    "                loss_pku = -1 * torch.sum(F.logsigmoid(-1 * torch.einsum(\"nj , j -> n\", [neg_neig_embs, z1])))\n",
    "                loss_total += C * NEG_LOSS_RATIO  * loss_pku\n",
    "                \n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data2(filename='', add_public_foe=True):\n",
    "    adj_lists1   = defaultdict(set)\n",
    "    adj_lists1_1 = defaultdict(set)\n",
    "    adj_lists1_2 = defaultdict(set)\n",
    "    \n",
    "    adj_lists2   = defaultdict(set)\n",
    "    adj_lists2_1 = defaultdict(set)\n",
    "    \n",
    "    adj_lists2_2 = defaultdict(set)\n",
    "    adj_lists3   = defaultdict(set)\n",
    "\n",
    "\n",
    "    with open(filename) as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            info = line.strip().split()\n",
    "            person1 = int(info[0])  # src\n",
    "            person2 = int(info[1])  # dst\n",
    "            v = int(info[2])  # signed edge\n",
    "            adj_lists3[person2].add(person1)  # 构建无向图连接的边\n",
    "            adj_lists3[person1].add(person2)\n",
    "\n",
    "            if v == 1:  # positive\n",
    "                adj_lists1[person1].add(person2)  # positive的无向图边\n",
    "                adj_lists1[person2].add(person1)\n",
    "\n",
    "                adj_lists1_1[person1].add(person2)  # positive的有向图边; u->v\n",
    "                adj_lists1_2[person2].add(person1)  # v->u\n",
    "            else:  # negative\n",
    "                adj_lists2[person1].add(person2)\n",
    "                adj_lists2[person2].add(person1)\n",
    "\n",
    "                adj_lists2_1[person1].add(person2)  # u->v\n",
    "                adj_lists2_2[person2].add(person1)\n",
    "\n",
    "\n",
    "    return adj_lists1, adj_lists1_1, adj_lists1_2, adj_lists2, adj_lists2_1, adj_lists2_2, adj_lists3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emb(num_nodes, fpath):\n",
    "    dim = 0\n",
    "    embeddings = 0\n",
    "    with open(fpath) as f:\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            if i == 0:\n",
    "                dim = int(line.split()[1])\n",
    "                embeddings = np.random.rand(num_nodes, dim)\n",
    "            else:\n",
    "                line_l = line.split()\n",
    "                node = line_l[0]\n",
    "                emb = [float(j) for j in line_l[1: ]]\n",
    "                assert len(emb) == dim\n",
    "                embeddings[int(node)] = np.array(emb)\n",
    "                \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run( dataset='bitcoin_alpha', k=2):\n",
    "    num_nodes = DATASET_NUM_DIC[dataset] + 3  # 节点数量\n",
    "\n",
    "    # adj_lists1, adj_lists2, adj_lists3 = load_data(k, dataset)\n",
    "    filename = r'C:\\Users\\sss\\Desktop\\SiGAT/experiment-data/{}-train-{}.edgelist'.format(dataset, k)\n",
    "    adj_lists1, adj_lists1_1, adj_lists1_2, adj_lists2, adj_lists2_1, adj_lists2_2, adj_lists3 = load_data2(filename, add_public_foe=False)\n",
    "    print(k, dataset, 'data load!')\n",
    "    \n",
    "    features = nn.Embedding(num_nodes, NODE_FEAT_SIZE)  # 建立节点embedding\n",
    "    features.weight.requires_grad = True\n",
    "\n",
    "    features.to(DEVICES)\n",
    "    # 邻接矩阵集合, balance theory\n",
    "    adj_lists = [adj_lists1, adj_lists1_1, adj_lists1_2, adj_lists2, adj_lists2_1, adj_lists2_2]\n",
    "\n",
    "\n",
    "    # 抽取点边关系\n",
    "    fea_model = FeaExtra(dataset=dataset, k=k)\n",
    "\n",
    "    adj_additions1 = [defaultdict(set) for _ in range(16)]  # positive三角形关系的list\n",
    "    adj_additions2 = [defaultdict(set) for _ in range(16)]  # negative三角形关系的list\n",
    "    a, b = 0, 0\n",
    "    # 三角形关系统计\n",
    "    # u->v positive的三角形统计\n",
    "    for i in adj_lists1_1:\n",
    "        for j in adj_lists1_1[i]:\n",
    "            v_list = fea_model.feature_part2(i, j)\n",
    "            for index, v in enumerate(v_list):\n",
    "                if v > 0:\n",
    "                    adj_additions1[index][i].add(j)\n",
    "                    a += 1\n",
    "    # u->v negative的三角形统计\n",
    "    for i in adj_lists2_1:\n",
    "        for j in adj_lists2_1[i]:\n",
    "            v_list = fea_model.feature_part2(i, j)\n",
    "            for index, v in enumerate(v_list):\n",
    "                if v > 0:\n",
    "                    adj_additions2[index][i].add(j)\n",
    "                    b += 1\n",
    "    assert a > 0, 'positive something wrong'\n",
    "    assert b > 0, 'negative something wrong'\n",
    "\n",
    "    # 38 motifs\n",
    "    adj_lists = adj_lists + adj_additions1 + adj_additions2\n",
    "    \n",
    "    #adj_lists = adj_lists + adj_additions1 + adj_additions2 + [adj_lists3]\n",
    "    ########################\n",
    "\n",
    "    # 2\n",
    "    # adj_lists = [adj_lists1, adj_lists2]\n",
    "\n",
    "    # 6\n",
    "    # adj_lists = [adj_lists1, adj_lists1_1, adj_lists1_2, adj_lists2, adj_lists2_1, adj_lists2_2]\n",
    "\n",
    "    # 18\n",
    "    # adj_lists = adj_lists + adj_additions0\n",
    "\n",
    "    print(len(adj_lists), 'motifs')\n",
    "\n",
    "    def func(adj_list):\n",
    "        edges = []\n",
    "        for a in adj_list:\n",
    "            for b in adj_list[a]:\n",
    "                edges.append((a, b))  # 获取点边关系\n",
    "        edges = np.array(edges)\n",
    "        adj = sp.sparse.csr_matrix((np.ones(len(edges)), (edges[:,0], edges[:,1])), shape=(num_nodes, num_nodes))  # 构建稀疏矩阵\n",
    "        return adj\n",
    "\n",
    "    adj_lists = list(map(func, adj_lists))  # 每个motifs的邻接矩阵\n",
    "    features_lists = [features for _ in range(len(adj_lists))]  # 每个motifs特征\n",
    "    aggs = [AttentionAggregator(features, NODE_FEAT_SIZE, NODE_FEAT_SIZE, num_nodes) for features, adj in\n",
    "            zip(features_lists, adj_lists)]\n",
    "\n",
    "    enc1 = Encoder(features_lists, NODE_FEAT_SIZE, EMBEDDING_SIZE1, adj_lists, aggs)  # motifs特征组合在一起\n",
    "\n",
    "    model = SiGAT(enc1)\n",
    "    model.to(DEVICES)\n",
    "    \n",
    "    # print(model.train())\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(\n",
    "            lambda p: p.requires_grad,\n",
    "            list(model.parameters()) + list(enc1.parameters()) + list(features.parameters())\n",
    "        ),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS + 2):\n",
    "        total_loss = []\n",
    "        if epoch % INTERVAL_PRINT == 1: # !! 0\n",
    "            model.eval()\n",
    "            all_embedding = np.zeros((NUM_NODE, EMBEDDING_SIZE1))\n",
    "            for i in range(0, NUM_NODE, BATCH_SIZE):\n",
    "                begin_index = i\n",
    "                end_index = i + BATCH_SIZE if i + BATCH_SIZE < NUM_NODE else NUM_NODE\n",
    "                values = np.arange(begin_index, end_index)\n",
    "                embed = model.forward(values.tolist())\n",
    "                embed = embed.data.cpu().numpy()\n",
    "                all_embedding[begin_index: end_index] = embed\n",
    "\n",
    "            fpath = os.path.join(OUTPUT_DIR, 'embedding-{}-{}-{}.npy'.format(dataset, k, str(epoch)) )\n",
    "            np.save(fpath, all_embedding)\n",
    "            model.train()\n",
    "\n",
    "        time1 = time.time()\n",
    "        nodes_pku = np.random.permutation(NUM_NODE).tolist()  # 打乱节点\n",
    "        for batch in range(NUM_NODE // BATCH_SIZE):\n",
    "            optimizer.zero_grad()\n",
    "            b_index = batch * BATCH_SIZE\n",
    "            e_index = (batch + 1) * BATCH_SIZE\n",
    "            nodes = nodes_pku[b_index:e_index]  # minbatch中的节点\n",
    "\n",
    "            loss = model.criterion(\n",
    "                nodes, adj_lists1, adj_lists2\n",
    "            )\n",
    "            total_loss.append(loss.data.cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f'epoch: {epoch}, loss: {np.sum(total_loss)}, time: {time.time()-time1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('NUM_NODE', NUM_NODE)\n",
    "    print('WEIGHT_DECAY', WEIGHT_DECAY)\n",
    "    print('NODE_FEAT_SIZE', NODE_FEAT_SIZE)\n",
    "    print('EMBEDDING_SIZE1', EMBEDDING_SIZE1)\n",
    "    print('LEARNING_RATE', LEARNING_RATE)\n",
    "    print('BATCH_SIZE', BATCH_SIZE)\n",
    "    print('EPOCHS', EPOCHS)\n",
    "    print('DROUPOUT', DROUPOUT)\n",
    "    run(dataset=args.dataset, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_NODE 3783\n",
      "WEIGHT_DECAY 0.0001\n",
      "NODE_FEAT_SIZE 20\n",
      "EMBEDDING_SIZE1 20\n",
      "LEARNING_RATE 0.0005\n",
      "BATCH_SIZE 500\n",
      "EPOCHS 100\n",
      "DROUPOUT 0.0\n",
      "1 bitcoin_alpha data load!\n",
      "38 motifs\n",
      "SiGAT(\n",
      "  (enc): Encoder(\n",
      "    (agg_0): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_1): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_2): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_3): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_4): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_5): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_6): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_7): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_8): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_9): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_10): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_11): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_12): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_13): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_14): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_15): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_16): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_17): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_18): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_19): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_20): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_21): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_22): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_23): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_24): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_25): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_26): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_27): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_28): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_29): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_30): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_31): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_32): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_33): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_34): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_35): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_36): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (agg_37): AttentionAggregator(\n",
      "      (features): Embedding(3786, 20)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (speical_spmm): SpecialSpmm()\n",
      "      (out_linear_layer): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (nonlinear_layer): Sequential(\n",
      "      (0): Linear(in_features=780, out_features=20, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\optim\\adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 46128.16796875, time: 12.924446105957031\n",
      "epoch: 1, loss: 26664.87890625, time: 14.247902870178223\n",
      "epoch: 2, loss: 19646.0390625, time: 10.90584421157837\n",
      "epoch: 3, loss: 16484.76171875, time: 10.223539352416992\n",
      "epoch: 4, loss: 13477.919921875, time: 11.071397542953491\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-1fd97d3152d5>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EPOCHS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DROUPOUT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDROUPOUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-61-1ef2b7416375>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(dataset, k)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'epoch: {epoch}, loss: {np.sum(total_loss)}, time: {time.time()-time1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0m_is_legacy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# _forward_cls is defined by derived class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
